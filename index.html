<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SeqBench: A comprehensive benchmark for evaluating sequential narrative coherence in text-to-video generation models.">
  <meta name="keywords" content="text-to-video, video generation, benchmark, sequential narrative, temporal coherence, T2V models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <style>
    .publication-title {
      font-family: 'Google Sans', sans-serif;
    }
    
    .hero.teaser {
      background: white;
      color: #333;
    }
    
    .teaser .hero-body {
      padding: 3rem 1.5rem;
    }
    
    .result-table {
      margin: 2rem 0;
      overflow-x: auto;
    }
    
    .result-table table {
      font-size: 0.85rem;
    }
    
    .methodology-step {
      background: #f8f9fa;
      border-radius: 8px;
      padding: 1.5rem;
      margin: 1rem 0;
      border-left: 4px solid #3273dc;
    }
    
    .dataset-category {
      background: white;
      border-radius: 8px;
      padding: 1.5rem;
      margin: 1rem 0;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .metric-comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin: 2rem 0;
    }
    
    @media (max-width: 768px) {
      .metric-comparison {
        grid-template-columns: 1fr;
      }
    }
    
    .highlight-number {
      font-size: 2rem;
      font-weight: bold;
      color: #3273dc;
    }
    
    .failure-mode {
      background: #fff5f5;
      border: 1px solid #fed7d7;
      border-radius: 8px;
      padding: 1rem;
      margin: 0.5rem 0;
    }
    
    .performance-card {
      background: white;
      border-radius: 8px;
      padding: 1.5rem;
      text-align: center;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      transition: transform 0.2s;
    }
    
    .performance-card:hover {
      transform: translateY(-2px);
    }
    
    .best-score {
      background: #e8f5e8;
      font-weight: bold;
    }
    
    .figure-container {
      text-align: center;
      margin: 2rem 0;
    }
    
    .figure-container img {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 16px rgba(0,0,0,0.1);
    }
    
    .video-gallery {
      background: #f8f9fa;
      padding: 2rem;
      border-radius: 12px;
      margin: 2rem 0;
    }
    
    .filter-controls {
      display: flex;
      flex-wrap: wrap;
      gap: 0.8rem;
      margin-bottom: 2rem;
      justify-content: center;
      align-items: center;
    }
    
    .filter-btn {
      padding: 0.4rem 0.8rem;
      border: 2px solid #3273dc;
      background: white;
      color: #3273dc;
      border-radius: 16px;
      cursor: pointer;
      transition: all 0.3s;
      font-size: 0.85rem;
      white-space: nowrap;
    }
    
    .filter-btn:hover, .filter-btn.active {
      background: #3273dc;
      color: white;
    }
    
    .video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 1.2rem;
      margin-top: 2rem;
    }
    
    @media (max-width: 768px) {
      .video-grid {
        grid-template-columns: 1fr;
        gap: 1rem;
      }
    }
    
    @media (min-width: 1200px) {
      .video-grid {
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 1.5rem;
      }
    }
    
    .video-card {
      background: white;
      border-radius: 8px;
      padding: 1rem;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      transition: transform 0.2s;
    }
    
    .video-card:hover {
      transform: translateY(-2px);
    }
    
    .video-placeholder {
      width: 100%;
      height: 200px;
      background: linear-gradient(45deg, #f0f0f0, #e0e0e0);
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      margin-bottom: 1rem;
      position: relative;
      overflow: hidden;
    }
    
    .video-placeholder::before {
      content: "üìπ";
      font-size: 3rem;
      opacity: 0.5;
    }
    
    .video-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      margin-top: 0.5rem;
    }
    
    .video-tag {
      background: #e3f2fd;
      color: #1976d2;
      padding: 0.2rem 0.5rem;
      border-radius: 12px;
      font-size: 0.8rem;
    }
    
    .human-eval-section {
      background: #f8f9fa;
      padding: 2rem;
      border-radius: 12px;
      margin: 2rem 0;
    }
    
    .eval-controls {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin-bottom: 2rem;
      justify-content: center;
    }
    
    .eval-table {
      overflow-x: auto;
      background: white;
      border-radius: 8px;
      padding: 1rem;
    }
    
    .eval-table table {
      font-size: 0.8rem;
    }
    
    .model-row {
      border-left: 4px solid #3273dc;
    }
    
    .category-header {
      background: #e3f2fd;
      font-weight: bold;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Authors</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Institute</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/AcmmmVideobench/Acmmm2025_video_benchmark"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="figure-container">
        <!-- ÊõøÊç¢‰∏∫ÂÆûÈôÖÁöÑ‰∏ªÂõæ -->
        <img src="./static/images/main_fig.jpg" alt="Sequential narrative generation failures in current T2V models" 
             style="max-width: 100%; background: white; padding: 1rem; border-radius: 12px;">
        <figcaption style="margin-top: 1rem; color: #666; font-size: 1.1rem;">
          Examples of sequential narrative generation failures in current T2V models. 
          Each type demonstrates specific failure modes that SeqBench is designed to detect and evaluate.
        </figcaption>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Text-to-video (T2V) generation models have made significant progress in creating visually appealing videos. 
          However, they struggle with generating coherent sequential narratives that require logical progression through multiple events. 
          Existing T2V benchmarks primarily focus on visual quality metrics but fail to evaluate narrative coherence over extended sequences.
          </p>
          <p>
          To bridge this gap, we present <span style="font-weight: bold;">SeqBench</span>, a comprehensive benchmark for evaluating sequential narrative coherence in T2V generation.
          SeqBench includes a carefully designed dataset of 320 prompts spanning various narrative complexities, with 2,560 human-annotated videos generated from 8 state-of-the-art T2V models. 
          Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic evaluation metric, 
          which can efficiently capture long-range dependencies and temporal ordering while maintaining computational efficiency.
          Our DTG-based metric demonstrates a strong correlation with human annotations. 
          </p>
          <p>
          Through systematic evaluation using SeqBench, we reveal critical limitations in current T2V models: failure to maintain consistent object states across multi-action sequences, 
          physically implausible results in multi-object scenarios, and difficulties in preserving realistic timing and ordering relationships between sequential actions. 
          SeqBench provides the first systematic framework for evaluating narrative coherence in T2V generation and offers concrete insights for improving sequential reasoning capabilities in future models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Dataset Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Dataset Overview</h2>
        
        <div class="columns">
          <div class="column is-half">
            <div class="dataset-category">
              <h4 class="title is-4">Key Statistics</h4>
              <div class="columns is-multiline">
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">320</div>
                  <p>Carefully Designed Prompts</p>
                </div>
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">2,560</div>
                  <p>Human-Annotated Videos</p>
                </div>
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">8</div>
                  <p>State-of-the-art T2V Models</p>
                </div>
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">4</div>
                  <p>Content Categories</p>
                </div>
              </div>
            </div>
          </div>
          
          <div class="column is-half">
            <div class="dataset-category">
              <h4 class="title is-4">Content Categories</h4>
              <div class="content">
                <p><strong>üêæ Animal:</strong> Animal behaviors and interactions, from simple locomotion to complex predatory behaviors</p>
                <p><strong>üë§ Human:</strong> Human activities across various contexts, from daily routines to social interactions</p>
                <p><strong>üì¶ Object:</strong> Inanimate objects and their transformations, movements, or interactions</p>
                <p><strong>‚ú® Imaginary:</strong> Fantastical, supernatural, or stylized content beyond realistic constraints</p>
              </div>
            </div>
          </div>
        </div>

        <div class="columns">
          <div class="column">
            <div class="dataset-category">
              <h4 class="title is-4">Difficulty Levels</h4>
              <div class="columns is-multiline">
                <div class="column is-half">
                  <p><strong>SSSA:</strong> Single Subject-Single Action</p>
                  <p><strong>SSMA:</strong> Single Subject-Multi Action</p>
                </div>
                <div class="column is-half">
                  <p><strong>MSSA:</strong> Multi Subject-Single Action</p>
                  <p><strong>MSMA:</strong> Multi Subject-Multi Action</p>
                </div>
              </div>
            </div>
          </div>
          
          <div class="column">
            <div class="dataset-category">
              <h4 class="title is-4">Temporal Orders</h4>
              <div class="content">
                <p><strong>SS:</strong> Strictly Sequential - Actions follow predetermined logical sequence</p>
                <p><strong>FO:</strong> Flexible Order - Actions can occur in varying orders while maintaining coherence</p>
                <p><strong>SI:</strong> Simultaneous - Concurrent actions testing parallel process coordination</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Methodology Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Dynamic Temporal Graph (DTG) Evaluation</h2>
        
        <!-- DTG Method Figure -->
        <div class="figure-container">
          <img src="./static/images/video_bench_fig_3.png" alt="Dynamic Temporal Graph evaluation framework" 
               style="max-width: 100%;">
          <figcaption style="margin-top: 1rem; color: #666; font-size: 1rem;">
            Overview of the Dynamic Temporal Graph (DTG) evaluation framework showing temporal decomposition, 
            adaptive graph extraction, and dependency filtering processes.
          </figcaption>
        </div>
        
        <div class="content has-text-centered">
          <p class="is-size-5">Our evaluation framework assesses videos across two complementary dimensions</p>
        </div>

        <div class="metric-comparison">
          <div class="performance-card">
            <h4 class="title is-4">üìä Visual Details Evaluation</h4>
            <div class="content">
              <p>Assesses visual quality, object fidelity, and scene composition using frame-level analysis</p>
              <ul style="text-align: left;">
                <li>Frame-level scene graph extraction</li>
                <li>Object presence and attribute correctness</li>
                <li>Spatial relationship accuracy</li>
                <li>Scene composition quality</li>
              </ul>
            </div>
          </div>
          
          <div class="performance-card">
            <h4 class="title is-4">üé¨ Narrative Coherence Evaluation</h4>
            <div class="content">
              <p>Measures temporal consistency and sequential logic using Dynamic Temporal Graphs</p>
              <ul style="text-align: left;">
                <li>Temporal decomposition</li>
                <li>Dynamic graph extraction</li>
                <li>Question-aware feature emphasis</li>
                <li>Dependency filtering</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="methodology-step">
          <h4 class="title is-4">üîç Key Innovation: Adaptive Graph Extraction</h4>
          <div class="content">
            <p>Traditional scene graph extraction uses static templates that may miss narrative-specific details. Our <strong>Dynamic Temporal Graph</strong> approach:</p>
            <ul>
              <li><strong>Dynamic Prompt Generation:</strong> Customizes graph extraction prompts based on specific evaluation questions</li>
              <li><strong>Question-aware Feature Emphasis:</strong> Prioritizes tracking of exact features needed for accurate evaluation</li>
              <li><strong>Multi-frame Analysis:</strong> Extracts scene graphs from 15 distributed frames using adapted prompts</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Video Gallery Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Human Category Video Examples</h2>
    
    <div class="video-gallery">
      <div class="content has-text-centered">
        <p class="is-size-5">Explore Human category video examples across all 8 models and difficulty levels</p>
        <p class="is-size-6" style="color: #666; margin-top: 0.5rem;">
          Featuring 64 videos (8 models √ó 8 difficulty levels) from our comprehensive human evaluation benchmark
        </p>
        <p class="is-size-7" style="color: #888; margin-top: 0.5rem;">
          Videos are sorted by performance score. Use filters to explore specific models or difficulty levels.
        </p>
      </div>
      
      <div class="filter-controls">
        <button class="filter-btn active" data-filter="all">All Videos</button>
        <button class="filter-btn" data-filter="human">üë§ Human</button>
        <div style="border-left: 2px solid #ddd; height: 20px; margin: 0 0.5rem;"></div>
        <button class="filter-btn" data-filter="kling">Kling 2.0</button>
        <button class="filter-btn" data-filter="hailuo">Hailuo T2V-01</button>
        <button class="filter-btn" data-filter="pika">Pika 2.2</button>
        <button class="filter-btn" data-filter="sora">Sora</button>
        <button class="filter-btn" data-filter="luma">Luma Ray2</button>
        <button class="filter-btn" data-filter="veo">Veo 2.0</button>
        <button class="filter-btn" data-filter="gen3">Runway Gen3</button>
        <button class="filter-btn" data-filter="cogvideo">Cogvideo 1.5</button>
        <div style="border-left: 2px solid #ddd; height: 20px; margin: 0 0.5rem;"></div>
        <button class="filter-btn" data-filter="sssa">SSSA</button>
        <button class="filter-btn" data-filter="mssa">MSSA</button>
        <button class="filter-btn" data-filter="ssma_fo">SSMA-FO</button>
        <button class="filter-btn" data-filter="ssma_sim">SSMA-SI</button>
        <button class="filter-btn" data-filter="ssma_ss">SSMA-SS</button>
        <button class="filter-btn" data-filter="msma_fo">MSMA-FO</button>
        <button class="filter-btn" data-filter="msma_sim">MSMA-SI</button>
        <button class="filter-btn" data-filter="msma_ss">MSMA-SS</button>
      </div>
      
      <div class="video-grid" id="videoGrid">
        <!-- Video examples will be populated here -->
      </div>
      
      <div id="videoStats" style="text-align: center; margin-top: 2rem; padding: 1rem; background: white; border-radius: 8px;">
        <p class="is-size-6" style="color: #666;">
          Showing <span id="visibleCount">64</span> of <span id="totalCount">64</span> videos
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experimental Results</h2>
    
    <div class="content has-text-centered">
      <p class="is-size-5">Evaluation of 8 state-of-the-art T2V models reveals significant gaps between visual quality and narrative coherence</p>
    </div>

    <!-- Visual Details Results -->
    <div class="result-table">
      <h3 class="title is-4">Visual Details Evaluation Results</h3>
      <div style="overflow-x: auto;">
        <table class="table is-striped is-fullwidth">
          <thead>
            <tr>
              <th>Model</th>
              <th>SSMA_SS</th>
              <th>SSMA_FO</th>
              <th>SSMA_SI</th>
              <th>MSMA_SS</th>
              <th>MSMA_FO</th>
              <th>MSMA_SI</th>
              <th>SSSA</th>
              <th>MSSA</th>
              <th>Avg. Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Kling 2.0</strong></td>
              <td class="best-score">0.819</td>
              <td class="best-score">0.839</td>
              <td class="best-score">0.823</td>
              <td>0.693</td>
              <td class="best-score">0.734</td>
              <td class="best-score">0.713</td>
              <td>0.774</td>
              <td class="best-score">0.804</td>
              <td class="best-score">0.775</td>
            </tr>
            <tr>
              <td><strong>Cogvideo 1.5</strong></td>
              <td>0.806</td>
              <td>0.817</td>
              <td>0.814</td>
              <td class="best-score">0.700</td>
              <td>0.718</td>
              <td>0.711</td>
              <td class="best-score">0.780</td>
              <td>0.789</td>
              <td>0.767</td>
            </tr>
            <tr>
              <td><strong>Hailuo T2V-01</strong></td>
              <td>0.812</td>
              <td>0.826</td>
              <td>0.758</td>
              <td>0.654</td>
              <td>0.659</td>
              <td>0.650</td>
              <td>0.771</td>
              <td>0.780</td>
              <td>0.739</td>
            </tr>
            <tr>
              <td><strong>Pika 2.2</strong></td>
              <td>0.757</td>
              <td>0.762</td>
              <td>0.721</td>
              <td>0.565</td>
              <td>0.676</td>
              <td>0.595</td>
              <td>0.710</td>
              <td>0.733</td>
              <td>0.690</td>
            </tr>
            <tr>
              <td><strong>Sora</strong></td>
              <td>0.737</td>
              <td>0.764</td>
              <td>0.750</td>
              <td>0.549</td>
              <td>0.591</td>
              <td>0.608</td>
              <td>0.699</td>
              <td>0.693</td>
              <td>0.674</td>
            </tr>
            <tr>
              <td><strong>Luma Ray2</strong></td>
              <td>0.684</td>
              <td>0.681</td>
              <td>0.724</td>
              <td>0.518</td>
              <td>0.608</td>
              <td>0.543</td>
              <td>0.721</td>
              <td>0.676</td>
              <td>0.644</td>
            </tr>
            <tr>
              <td><strong>Veo 2.0</strong></td>
              <td>0.482</td>
              <td>0.585</td>
              <td>0.595</td>
              <td>0.523</td>
              <td>0.517</td>
              <td>0.476</td>
              <td>0.627</td>
              <td>0.578</td>
              <td>0.548</td>
            </tr>
            <tr>
              <td><strong>Runway Gen3</strong></td>
              <td>0.485</td>
              <td>0.552</td>
              <td>0.563</td>
              <td>0.383</td>
              <td>0.446</td>
              <td>0.442</td>
              <td>0.532</td>
              <td>0.470</td>
              <td>0.484</td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>

    <!-- Narrative Coherence Results -->
    <div class="result-table">
      <h3 class="title is-4">Narrative Coherence Evaluation Results</h3>
      <div style="overflow-x: auto;">
        <table class="table is-striped is-fullwidth">
          <thead>
            <tr>
              <th>Model</th>
              <th>SSMA_SS</th>
              <th>SSMA_FO</th>
              <th>SSMA_SI</th>
              <th>MSMA_SS</th>
              <th>MSMA_FO</th>
              <th>MSMA_SI</th>
              <th>SSSA</th>
              <th>MSSA</th>
              <th>Avg. Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Kling 2.0</strong></td>
              <td class="best-score">0.266</td>
              <td>0.209</td>
              <td>0.207</td>
              <td class="best-score">0.192</td>
              <td class="best-score">0.258</td>
              <td>0.228</td>
              <td>0.291</td>
              <td class="best-score">0.366</td>
              <td class="best-score">0.252</td>
            </tr>
            <tr>
              <td><strong>Hailuo T2V-01</strong></td>
              <td>0.212</td>
              <td class="best-score">0.230</td>
              <td>0.192</td>
              <td>0.179</td>
              <td>0.207</td>
              <td>0.199</td>
              <td class="best-score">0.345</td>
              <td>0.288</td>
              <td>0.231</td>
            </tr>
            <tr>
              <td><strong>Pika 2.2</strong></td>
              <td>0.219</td>
              <td>0.202</td>
              <td>0.194</td>
              <td>0.171</td>
              <td>0.238</td>
              <td class="best-score">0.229</td>
              <td>0.293</td>
              <td>0.277</td>
              <td>0.228</td>
            </tr>
            <tr>
              <td><strong>Cogvideo 1.5</strong></td>
              <td>0.222</td>
              <td>0.197</td>
              <td class="best-score">0.208</td>
              <td>0.189</td>
              <td>0.224</td>
              <td>0.191</td>
              <td>0.272</td>
              <td>0.235</td>
              <td>0.217</td>
            </tr>
            <tr>
              <td><strong>Veo 2.0</strong></td>
              <td>0.156</td>
              <td>0.180</td>
              <td>0.158</td>
              <td>0.184</td>
              <td>0.225</td>
              <td>0.190</td>
              <td>0.256</td>
              <td>0.262</td>
              <td>0.201</td>
            </tr>
            <tr>
              <td><strong>Luma Ray2</strong></td>
              <td>0.122</td>
              <td>0.174</td>
              <td>0.149</td>
              <td>0.171</td>
              <td>0.199</td>
              <td>0.146</td>
              <td>0.216</td>
              <td>0.262</td>
              <td>0.180</td>
            </tr>
            <tr>
              <td><strong>Sora</strong></td>
              <td>0.198</td>
              <td>0.161</td>
              <td>0.154</td>
              <td>0.123</td>
              <td>0.152</td>
              <td>0.171</td>
              <td>0.287</td>
              <td>0.180</td>
              <td>0.178</td>
            </tr>
            <tr>
              <td><strong>Runway Gen3</strong></td>
              <td>0.149</td>
              <td>0.137</td>
              <td>0.163</td>
              <td>0.115</td>
              <td>0.141</td>
              <td>0.163</td>
              <td>0.198</td>
              <td>0.170</td>
              <td>0.154</td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
</section>

<!-- Human Evaluation Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Human Evaluation Results</h2>
    
    <div class="human-eval-section">
      <div class="content has-text-centered">
        <p class="is-size-5">
          Detailed human evaluation across all models and categories with Overall, Action, and Consistency dimensions
        </p>
      </div>
      
      <div class="eval-controls">
        <button class="filter-btn active" onclick="showEvalCategory('all')">All Categories</button>
        <button class="filter-btn" onclick="showEvalCategory('animal')">üêæ Animal</button>
        <button class="filter-btn" onclick="showEvalCategory('human')">üë§ Human</button>
        <button class="filter-btn" onclick="showEvalCategory('imaginary')">‚ú® Imaginary</button>
        <button class="filter-btn" onclick="showEvalCategory('object')">üì¶ Object</button>
      </div>
      
      <div class="eval-table">
        <div style="overflow-x: auto;">
          <table class="table is-striped is-fullwidth" id="humanEvalTable">
            <thead>
              <tr>
                <th rowspan="2">Model</th>
                <th colspan="3">MSMA-FO</th>
                <th colspan="3">MSMA-SI</th>
                <th colspan="3">MSMA-SS</th>
                <th colspan="3">MSSA</th>
                <th colspan="3">SSMA-FO</th>
                <th colspan="3">SSMA-SI</th>
                <th colspan="3">SSMA-SS</th>
                <th colspan="3">SSSA</th>
              </tr>
              <tr>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
              </tr>
            </thead>
            <tbody id="humanEvalBody">
              <!-- Data will be populated by JavaScript -->
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX Section -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{seqbench2025,
  author    = {Anonymous Authors},
  title     = {SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models},
  journal   = {TBD},
  year      = {2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
// Human evaluation data from your provided table
const humanEvalData = {
  'cogvideo': {
    'Animal': [1.450000, 0.700000, 0.950000, 0.800000, 0.300000, 0.500000, 0.600000, 0.400000, 0.200000, 0.400000, 0.200000, 0.200000, 1.000000, 0.500000, 0.600000, 0.400000, 0.200000, 0.200000, 0.900000, 0.300000, 0.300000, 0.200000, 0.200000, 0.200000],
    'Human': [0.333333, 0.266667, 0.300000, 0.233333, 0.066667, 0.133333, 0.500000, 0.333333, 0.166667, 0.300000, 0.300000, 0.300000, 0.233333, 0.100000, 0.166667, 0.200000, 0.100000, 0.166667, 0.200000, 0.133333, 0.200000, 0.300000, 0.300000, 0.300000],
    'Imaginary': [0.566667, 0.566667, 0.133333, 0.466667, 0.216667, 0.400000, 0.583333, 0.533333, 0.050000, 0.400000, 0.650000, 0.250000, 0.650000, 0.600000, 0.400000, 0.650000, 0.650000, 0.250000, 0.750000, 0.550000, 0.550000, 0.650000, 0.650000, 0.250000],
    'Object': [0.800000, 0.300000, 0.500000, 1.050000, 0.350000, 0.700000, 0.750000, 0.700000, 0.050000, 0.500000, 0.550000, 0.750000, 0.850000, 0.250000, 0.550000, 0.550000, 0.400000, 0.750000, 0.700000, 0.250000, 0.550000, 0.550000, 0.400000, 0.750000]
  },
  'gen3': {
    'Animal': [0.100000, 0.100000, 0.050000, 0.200000, 0.400000, 0.350000, 0.150000, 0.000000, 0.700000, 0.600000, 0.150000, 0.100000, 0.350000, 0.150000, 0.150000, 0.300000, 0.350000, 0.150000, 0.450000, 0.200000, 0.200000, 0.300000, 0.250000, 0.150000, 0.100000],
    'Human': [0.233333, 0.133333, 0.233333, 0.133333, 0.100000, 0.100000, 0.333333, 0.200000, 0.133333, 0.300000, 0.350000, 0.150000, 0.350000, 0.300000, 0.350000, 0.350000, 0.200000, 0.300000, 0.400000, 0.300000, 0.350000, 0.350000, 0.150000, 0.150000, 0.100000],
    'Imaginary': [0.266667, 0.600000, 0.333333, 0.133333, 0.366667, 0.350000, 0.600000, 0.466667, 0.133333, 0.500000, 0.250000, 0.300000, 0.450000, 0.550000, 0.450000, 0.650000, 0.650000, 0.300000, 0.550000, 0.350000, 0.300000, 0.350000, 0.350000, 0.300000],
    'Object': [0.650000, 0.200000, 0.450000, 0.550000, 0.250000, 0.450000, 0.750000, 0.700000, 0.050000, 0.500000, 0.750000, 0.900000, 0.700000, 0.450000, 0.500000, 0.750000, 0.550000, 0.650000, 0.900000, 0.600000, 0.650000, 0.750000, 0.700000, 0.200000, 0.900000]
  },
  'hailuo': {
    'Animal': [1.150000, 0.750000, 0.600000, 1.000000, 0.900000, 0.900000, 0.900000, 0.900000, 0.000000, 0.600000, 0.650000, 0.550000, 0.800000, 0.800000, 0.600000, 0.650000, 0.650000, 0.550000, 0.650000, 0.650000, 0.550000, 1.000000, 0.650000, 0.650000, 0.550000],
    'Human': [0.733333, 0.500000, 0.366667, 0.700000, 0.350000, 0.500000, 0.700000, 0.533333, 0.266667, 0.250000, 0.700000, 0.400000, 0.600000, 0.450000, 0.650000, 0.650000, 0.400000, 0.400000, 0.650000, 0.650000, 0.400000, 0.650000, 0.650000, 0.400000, 0.400000],
    'Imaginary': [0.566667, 0.500000, 0.200000, 0.766667, 0.600000, 0.666667, 0.700000, 0.700000, 0.000000, 0.600000, 0.450000, 0.550000, 0.650000, 0.550000, 0.550000, 0.650000, 0.650000, 0.550000, 0.600000, 0.600000, 0.550000, 0.800000, 0.550000, 0.550000, 0.550000],
    'Object': [1.100000, 0.600000, 0.700000, 0.650000, 0.450000, 0.500000, 0.700000, 0.700000, 0.000000, 0.450000, 0.500000, 0.750000, 0.650000, 0.500000, 0.500000, 0.650000, 0.650000, 0.500000, 0.500000, 0.500000, 0.500000, 0.850000, 0.500000, 0.500000, 0.750000]
  },
  'luma': {
    'Animal': [0.900000, 0.650000, 0.250000, 0.800000, 0.600000, 0.750000, 0.850000, 0.800000, 0.050000, 0.650000, 0.600000, 0.450000, 0.650000, 0.600000, 0.450000, 0.650000, 0.650000, 0.450000, 0.750000, 0.750000, 0.450000, 0.800000, 0.650000, 0.450000, 0.450000],
    'Human': [0.533333, 0.333333, 0.200000, 0.500000, 0.350000, 0.300000, 0.600000, 0.500000, 0.100000, 0.450000, 0.650000, 0.350000, 0.350000, 0.300000, 0.200000, 0.550000, 0.450000, 0.300000, 0.600000, 0.350000, 0.300000, 0.650000, 0.350000, 0.250000, 0.300000],
    'Imaginary': [0.666667, 0.750000, 0.350000, 0.500000, 0.700000, 0.550000, 0.900000, 0.800000, 0.100000, 0.700000, 0.550000, 0.600000, 0.800000, 0.750000, 0.600000, 0.750000, 0.750000, 0.600000, 0.850000, 0.800000, 0.550000, 0.900000, 0.800000, 0.550000, 0.550000],
    'Object': [1.250000, 0.600000, 0.700000, 0.800000, 0.350000, 0.400000, 1.000000, 0.900000, 0.200000, 0.050000, 0.650000, 0.800000, 0.550000, 0.350000, 0.450000, 0.950000, 0.850000, 0.450000, 0.700000, 0.550000, 0.450000, 0.650000, 0.800000, 0.250000, 0.800000]
  },
  'pika': {
    'Animal': [1.150000, 0.350000, 0.750000, 0.700000, 0.350000, 0.900000, 0.900000, 0.750000, 0.200000, 0.000000, 0.650000, 0.550000, 0.950000, 0.900000, 0.650000, 0.550000, 0.550000, 0.650000, 0.900000, 0.850000, 0.650000, 0.550000, 0.250000, 0.300000],
    'Human': [0.433333, 0.466667, 0.233333, 0.433333, 0.366667, 0.200000, 0.566667, 0.400000, 0.166667, 0.350000, 0.400000, 0.250000, 0.350000, 0.300000, 0.300000, 0.450000, 0.450000, 0.300000, 0.700000, 0.350000, 0.300000, 0.250000, 0.300000, 0.000000],
    'Imaginary': [1.033333, 0.666667, 0.533333, 1.033333, 0.800000, 0.700000, 0.800000, 0.800000, 0.000000, 0.700000, 0.850000, 0.900000, 0.850000, 0.750000, 0.850000, 0.900000, 0.900000, 0.750000, 1.050000, 0.850000, 0.850000, 1.050000, 0.850000, 0.900000],
    'Object': [0.900000, 0.600000, 0.400000, 1.150000, 0.650000, 0.800000, 0.900000, 0.900000, 0.300000, 0.350000, 0.500000, 0.700000, 0.650000, 0.400000, 0.450000, 0.900000, 0.850000, 0.450000, 0.750000, 0.650000, 0.450000, 0.750000, 0.650000, 0.700000]
  },
  'sora': {
    'Animal': [0.450000, 0.500000, 0.150000, 0.500000, 0.400000, 0.100000, 0.650000, 0.550000, 0.050000, 0.400000, 0.400000, 0.300000, 0.400000, 0.400000, 0.300000, 0.550000, 0.500000, 0.300000, 0.450000, 0.400000, 0.300000, 0.700000, 0.400000, 0.300000],
    'Human': [0.333333, 0.166667, 0.133333, 0.233333, 0.066667, 0.066667, 0.350000, 0.300000, 0.050000, 0.350000, 0.300000, 0.350000, 0.300000, 0.200000, 0.200000, 0.350000, 0.350000, 0.200000, 0.300000, 0.300000, 0.200000, 0.350000, 0.200000, 0.350000],
    'Imaginary': [0.133333, 0.566667, 0.333333, 0.166667, 0.166667, 0.150000, 0.300000, 0.450000, 0.200000, 0.050000, 0.250000, 0.350000, 0.250000, 0.500000, 0.350000, 0.500000, 0.500000, 0.350000, 0.250000, 0.450000, 0.350000, 0.550000, 0.500000, 0.350000],
    'Object': [0.700000, 0.400000, 0.500000, 0.850000, 0.550000, 0.300000, 0.550000, 0.550000, 0.300000, 0.050000, 0.750000, 0.550000, 0.650000, 0.650000, 0.550000, 0.750000, 0.800000, 0.550000, 0.700000, 0.700000, 0.550000, 1.050000, 0.300000, 0.900000]
  },
  'veo': {
    'Animal': [1.400000, 0.550000, 0.850000, 1.400000, 0.700000, 1.100000, 0.900000, 0.900000, 0.000000, 0.700000, 0.450000, 0.150000, 0.800000, 0.650000, 0.450000, 0.900000, 0.850000, 0.450000, 0.900000, 0.850000, 0.450000, 0.850000, 0.800000, 0.150000, 0.150000],
    'Human': [0.866667, 0.266667, 0.766667, 0.466667, 0.200000, 0.666667, 0.600000, 0.500000, 0.400000, 0.450000, 0.850000, 0.700000, 0.550000, 0.300000, 0.550000, 0.700000, 0.650000, 0.550000, 0.850000, 0.650000, 0.450000, 0.850000, 0.850000, 0.450000, 0.700000],
    'Imaginary': [0.600000, 0.600000, 0.400000, 0.633333, 0.566667, 0.400000, 0.600000, 0.550000, 0.050000, 0.350000, 0.400000, 0.550000, 0.500000, 0.350000, 0.400000, 0.850000, 0.800000, 0.550000, 0.700000, 0.650000, 0.550000, 1.000000, 0.850000, 0.550000, 0.550000],
    'Object': [1.250000, 0.750000, 0.700000, 1.250000, 0.550000, 0.700000, 0.900000, 0.900000, 0.000000, 0.150000, 0.850000, 0.650000, 0.900000, 0.850000, 0.650000, 0.900000, 0.850000, 0.650000, 1.100000, 0.900000, 0.650000, 1.100000, 0.900000, 0.350000, 0.850000]
  }
};

// All Human category videos - representative selection
const videoExamples = [
  // Kling 2.0 videos
  { title: "MSMA-FO - Kling 2.0", category: "human", difficulty: "msma_fo", model: "Kling 2.0", modelKey: "kling", score: 1.667, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/kling/9.mp4", index: 9 },
  { title: "MSMA-SI - Kling 2.0", category: "human", difficulty: "msma_sim", model: "Kling 2.0", modelKey: "kling", score: 1.667, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/kling/7.mp4", index: 7 },
  { title: "MSMA-SS - Kling 2.0", category: "human", difficulty: "msma_ss", model: "Kling 2.0", modelKey: "kling", score: 1.0, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/kling/5.mp4", index: 5 },
  { title: "MSSA - Kling 2.0", category: "human", difficulty: "mssa", model: "Kling 2.0", modelKey: "kling", score: 2.0, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/kling/3.mp4", index: 3 },
  { title: "SSMA-FO - Kling 2.0", category: "human", difficulty: "ssma_fo", model: "Kling 2.0", modelKey: "kling", score: 1.5, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/kling/1.mp4", index: 1 },
  { title: "SSMA-SI - Kling 2.0", category: "human", difficulty: "ssma_sim", model: "Kling 2.0", modelKey: "kling", score: 1.5, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/kling/5.mp4", index: 5 },
  { title: "SSMA-SS - Kling 2.0", category: "human", difficulty: "ssma_ss", model: "Kling 2.0", modelKey: "kling", score: 1.5, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/kling/1.mp4", index: 1 },
  { title: "SSSA - Kling 2.0", category: "human", difficulty: "sssa", model: "Kling 2.0", modelKey: "kling", score: 2.0, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/kling/3.mp4", index: 3 },
  
  // Hailuo T2V-01 videos
  { title: "MSMA-FO - Hailuo T2V-01", category: "human", difficulty: "msma_fo", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.333, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/hailuo/2.mp4", index: 2 },
  { title: "MSMA-SI - Hailuo T2V-01", category: "human", difficulty: "msma_sim", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.0, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/hailuo/3.mp4", index: 3 },
  { title: "MSMA-SS - Hailuo T2V-01", category: "human", difficulty: "msma_ss", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.0, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/hailuo/1.mp4", index: 1 },
  { title: "MSSA - Hailuo T2V-01", category: "human", difficulty: "mssa", model: "Hailuo T2V-01", modelKey: "hailuo", score: 0.667, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/hailuo/4.mp4", index: 4 },
  { title: "SSMA-FO - Hailuo T2V-01", category: "human", difficulty: "ssma_fo", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.0, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/hailuo/6.mp4", index: 6 },
  { title: "SSMA-SI - Hailuo T2V-01", category: "human", difficulty: "ssma_sim", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.0, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/hailuo/8.mp4", index: 8 },
  { title: "SSMA-SS - Hailuo T2V-01", category: "human", difficulty: "ssma_ss", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.0, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/hailuo/2.mp4", index: 2 },
  { title: "SSSA - Hailuo T2V-01", category: "human", difficulty: "sssa", model: "Hailuo T2V-01", modelKey: "hailuo", score: 1.0, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/hailuo/10.mp4", index: 10 },

  // Pika 2.2 videos  
  { title: "MSMA-FO - Pika 2.2", category: "human", difficulty: "msma_fo", model: "Pika 2.2", modelKey: "pika", score: 0.667, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/pika/6.mp4", index: 6 },
  { title: "MSMA-SI - Pika 2.2", category: "human", difficulty: "msma_sim", model: "Pika 2.2", modelKey: "pika", score: 0.667, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/pika/1.mp4", index: 1 },
  { title: "MSMA-SS - Pika 2.2", category: "human", difficulty: "msma_ss", model: "Pika 2.2", modelKey: "pika", score: 1.0, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/pika/7.mp4", index: 7 },
  { title: "MSSA - Pika 2.2", category: "human", difficulty: "mssa", model: "Pika 2.2", modelKey: "pika", score: 0.667, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/pika/5.mp4", index: 5 },
  { title: "SSMA-FO - Pika 2.2", category: "human", difficulty: "ssma_fo", model: "Pika 2.2", modelKey: "pika", score: 0.667, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/pika/9.mp4", index: 9 },
  { title: "SSMA-SI - Pika 2.2", category: "human", difficulty: "ssma_sim", model: "Pika 2.2", modelKey: "pika", score: 0.667, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/pika/2.mp4", index: 2 },
  { title: "SSMA-SS - Pika 2.2", category: "human", difficulty: "ssma_ss", model: "Pika 2.2", modelKey: "pika", score: 1.0, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/pika/3.mp4", index: 3 },
  { title: "SSSA - Pika 2.2", category: "human", difficulty: "sssa", model: "Pika 2.2", modelKey: "pika", score: 0.667, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/pika/8.mp4", index: 8 },

  // Sora videos
  { title: "MSMA-FO - Sora", category: "human", difficulty: "msma_fo", model: "Sora", modelKey: "sora", score: 0.333, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/sora/1.mp4", index: 1 },
  { title: "MSMA-SI - Sora", category: "human", difficulty: "msma_sim", model: "Sora", modelKey: "sora", score: 0.333, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/sora/3.mp4", index: 3 },
  { title: "MSMA-SS - Sora", category: "human", difficulty: "msma_ss", model: "Sora", modelKey: "sora", score: 0.667, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/sora/4.mp4", index: 4 },
  { title: "MSSA - Sora", category: "human", difficulty: "mssa", model: "Sora", modelKey: "sora", score: 0.667, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/sora/1.mp4", index: 1 },
  { title: "SSMA-FO - Sora", category: "human", difficulty: "ssma_fo", model: "Sora", modelKey: "sora", score: 0.667, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/sora/4.mp4", index: 4 },
  { title: "SSMA-SI - Sora", category: "human", difficulty: "ssma_sim", model: "Sora", modelKey: "sora", score: 0.667, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/sora/5.mp4", index: 5 },
  { title: "SSMA-SS - Sora", category: "human", difficulty: "ssma_ss", model: "Sora", modelKey: "sora", score: 0.667, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/sora/6.mp4", index: 6 },
  { title: "SSSA - Sora", category: "human", difficulty: "sssa", model: "Sora", modelKey: "sora", score: 0.667, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/sora/2.mp4", index: 2 },

  // Luma Ray2 videos
  { title: "MSMA-FO - Luma Ray2", category: "human", difficulty: "msma_fo", model: "Luma Ray2", modelKey: "luma", score: 0.667, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/luma/1.mp4", index: 1 },
  { title: "MSMA-SI - Luma Ray2", category: "human", difficulty: "msma_sim", model: "Luma Ray2", modelKey: "luma", score: 1.0, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/luma/9.mp4", index: 9 },
  { title: "MSMA-SS - Luma Ray2", category: "human", difficulty: "msma_ss", model: "Luma Ray2", modelKey: "luma", score: 1.0, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/luma/4.mp4", index: 4 },
  { title: "MSSA - Luma Ray2", category: "human", difficulty: "mssa", model: "Luma Ray2", modelKey: "luma", score: 1.0, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/luma/6.mp4", index: 6 },
  { title: "SSMA-FO - Luma Ray2", category: "human", difficulty: "ssma_fo", model: "Luma Ray2", modelKey: "luma", score: 0.667, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/luma/7.mp4", index: 7 },
  { title: "SSMA-SI - Luma Ray2", category: "human", difficulty: "ssma_sim", model: "Luma Ray2", modelKey: "luma", score: 1.0, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/luma/3.mp4", index: 3 },
  { title: "SSMA-SS - Luma Ray2", category: "human", difficulty: "ssma_ss", model: "Luma Ray2", modelKey: "luma", score: 1.0, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/luma/8.mp4", index: 8 },
  { title: "SSSA - Luma Ray2", category: "human", difficulty: "sssa", model: "Luma Ray2", modelKey: "luma", score: 1.0, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/luma/1.mp4", index: 1 },

  // Veo 2.0 videos
  { title: "MSMA-FO - Veo 2.0", category: "human", difficulty: "msma_fo", model: "Veo 2.0", modelKey: "veo", score: 1.333, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/veo/2.mp4", index: 2 },
  { title: "MSMA-SI - Veo 2.0", category: "human", difficulty: "msma_sim", model: "Veo 2.0", modelKey: "veo", score: 1.0, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/veo/4.mp4", index: 4 },
  { title: "MSMA-SS - Veo 2.0", category: "human", difficulty: "msma_ss", model: "Veo 2.0", modelKey: "veo", score: 1.0, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/veo/5.mp4", index: 5 },
  { title: "MSSA - Veo 2.0", category: "human", difficulty: "mssa", model: "Veo 2.0", modelKey: "veo", score: 1.0, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/veo/7.mp4", index: 7 },
  { title: "SSMA-FO - Veo 2.0", category: "human", difficulty: "ssma_fo", model: "Veo 2.0", modelKey: "veo", score: 1.0, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/veo/9.mp4", index: 9 },
  { title: "SSMA-SI - Veo 2.0", category: "human", difficulty: "ssma_sim", model: "Veo 2.0", modelKey: "veo", score: 1.0, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/veo/1.mp4", index: 1 },
  { title: "SSMA-SS - Veo 2.0", category: "human", difficulty: "ssma_ss", model: "Veo 2.0", modelKey: "veo", score: 1.333, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/veo/10.mp4", index: 10 },
  { title: "SSSA - Veo 2.0", category: "human", difficulty: "sssa", model: "Veo 2.0", modelKey: "veo", score: 1.333, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/veo/6.mp4", index: 6 },

  // Runway Gen3 videos
  { title: "MSMA-FO - Runway Gen3", category: "human", difficulty: "msma_fo", model: "Runway Gen3", modelKey: "gen3", score: 0.333, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/gen3/2.mp4", index: 2 },
  { title: "MSMA-SI - Runway Gen3", category: "human", difficulty: "msma_sim", model: "Runway Gen3", modelKey: "gen3", score: 0.333, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/gen3/1.mp4", index: 1 },
  { title: "MSMA-SS - Runway Gen3", category: "human", difficulty: "msma_ss", model: "Runway Gen3", modelKey: "gen3", score: 0.667, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/gen3/4.mp4", index: 4 },
  { title: "MSSA - Runway Gen3", category: "human", difficulty: "mssa", model: "Runway Gen3", modelKey: "gen3", score: 0.667, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/gen3/6.mp4", index: 6 },
  { title: "SSMA-FO - Runway Gen3", category: "human", difficulty: "ssma_fo", model: "Runway Gen3", modelKey: "gen3", score: 0.667, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/gen3/5.mp4", index: 5 },
  { title: "SSMA-SI - Runway Gen3", category: "human", difficulty: "ssma_sim", model: "Runway Gen3", modelKey: "gen3", score: 0.667, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/gen3/7.mp4", index: 7 },
  { title: "SSMA-SS - Runway Gen3", category: "human", difficulty: "ssma_ss", model: "Runway Gen3", modelKey: "gen3", score: 0.667, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/gen3/8.mp4", index: 8 },
  { title: "SSSA - Runway Gen3", category: "human", difficulty: "sssa", model: "Runway Gen3", modelKey: "gen3", score: 0.667, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/gen3/9.mp4", index: 9 },

  // Cogvideo 1.5 videos
  { title: "MSMA-FO - Cogvideo 1.5", category: "human", difficulty: "msma_fo", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.333, description: "Multi Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_fo/cogvideo/1.mp4", index: 1 },
  { title: "MSMA-SI - Cogvideo 1.5", category: "human", difficulty: "msma_sim", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.333, description: "Multi Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_sim/cogvideo/2.mp4", index: 2 },
  { title: "MSMA-SS - Cogvideo 1.5", category: "human", difficulty: "msma_ss", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 1.0, description: "Multi Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/msma_ss/cogvideo/5.mp4", index: 5 },
  { title: "MSSA - Cogvideo 1.5", category: "human", difficulty: "mssa", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.667, description: "Multi Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/mssa/cogvideo/3.mp4", index: 3 },
  { title: "SSMA-FO - Cogvideo 1.5", category: "human", difficulty: "ssma_fo", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.333, description: "Single Subject-Multi Action (Flexible Order)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_fo/cogvideo/4.mp4", index: 4 },
  { title: "SSMA-SI - Cogvideo 1.5", category: "human", difficulty: "ssma_sim", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.333, description: "Single Subject-Multi Action (Simultaneous)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_sim/cogvideo/6.mp4", index: 6 },
  { title: "SSMA-SS - Cogvideo 1.5", category: "human", difficulty: "ssma_ss", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.333, description: "Single Subject-Multi Action (Strictly Sequential)", videoPath: "https://videobench.github.io/static/video_bench/human/ssma_ss/cogvideo/7.mp4", index: 7 },
  { title: "SSSA - Cogvideo 1.5", category: "human", difficulty: "sssa", model: "Cogvideo 1.5", modelKey: "cogvideo", score: 0.667, description: "Single Subject-Single Action", videoPath: "https://videobench.github.io/static/video_bench/human/sssa/cogvideo/8.mp4", index: 8 }
];

function populateVideoGallery() {
  const grid = document.getElementById('videoGrid');
  grid.innerHTML = '';
  
  videoExamples.forEach(video => {
    const card = document.createElement('div');
    card.className = `video-card ${video.category} ${video.difficulty} ${video.modelKey}`;
    card.innerHTML = `
      <div class="video-container" style="position: relative; width: 100%; height: 200px; border-radius: 8px; overflow: hidden; background: #f0f0f0;">
        <video 
          controls 
          style="width: 100%; height: 100%; object-fit: cover;"
          poster="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzAwIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSIjZjBmMGYwIi8+PHRleHQgeD0iNTAlIiB5PSI1MCUiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNiIgZmlsbD0iIzk5OSIgdGV4dC1hbmNob3I9Im1pZGRsZSIgZHk9Ii4zZW0iPvCfk7kgVmlkZW88L3RleHQ+PC9zdmc+"
          onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"
        >
          <source src="${video.videoPath}" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <div style="display: none; align-items: center; justify-content: center; height: 100%; color: #666; text-align: center; padding: 1rem; flex-direction: column;">
          <div style="font-size: 2rem; margin-bottom: 0.5rem;">üìπ</div>
          <div><strong>${video.title}</strong></div>
          <div style="font-size: 0.8rem; margin-top: 0.5rem; color: #999;">
            Video: ${video.videoPath}
          </div>
          <div style="font-size: 0.8rem; color: #999;">
            (Video file not accessible)
          </div>
        </div>
        <div style="position: absolute; bottom: 8px; right: 8px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.8rem;">
          Score: ${video.score}
        </div>
      </div>
      <h5 class="title is-6" style="margin-top: 1rem;">${video.title}</h5>
      <p class="is-size-7">${video.description}</p>
      <div class="video-tags">
        <span class="video-tag">${video.model}</span>
        <span class="video-tag">${video.category}</span>
        <span class="video-tag">${video.difficulty.toUpperCase().replace('_', '-')}</span>
      </div>
      <div style="margin-top: 0.5rem; font-size: 0.7rem; color: #666;">
        Index: ${video.index} | Path: ${video.videoPath.split('/').slice(-3).join('/')}
      </div>
    `;
    grid.appendChild(card);
  });
}

function filterVideos(filter, buttonElement) {
  const cards = document.querySelectorAll('.video-card');
  let visibleCount = 0;
  
  cards.forEach(card => {
    let shouldShow = false;
    
    if (filter === 'all') {
      shouldShow = true;
    } else {
      // Check if the card matches the filter
      shouldShow = card.classList.contains(filter);
    }
    
    if (shouldShow) {
      card.style.display = 'block';
      visibleCount++;
    } else {
      card.style.display = 'none';
    }
  });
  
  // Update statistics
  document.getElementById('visibleCount').textContent = visibleCount;
  document.getElementById('totalCount').textContent = cards.length;
  
  // Update active button
  document.querySelectorAll('.filter-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  if (buttonElement) {
    buttonElement.classList.add('active');
  }
}

function populateHumanEvalTable(category = 'all') {
  const tbody = document.getElementById('humanEvalBody');
  tbody.innerHTML = '';
  
  const models = ['cogvideo', 'gen3', 'hailuo', 'luma', 'pika', 'sora', 'veo'];
  const modelNames = {
    'cogvideo': 'Cogvideo 1.5',
    'gen3': 'Runway Gen3', 
    'hailuo': 'Hailuo T2V-01',
    'luma': 'Luma Ray2',
    'pika': 'Pika 2.2',
    'sora': 'Sora',
    'veo': 'Veo 2.0'
  };
  
  models.forEach(model => {
    if (category === 'all') {
      // Show average across all categories
      const categories = ['Animal', 'Human', 'Imaginary', 'Object'];
      const avgData = new Array(24).fill(0);
      
      categories.forEach(cat => {
        const data = humanEvalData[model][cat];
        data.forEach((val, idx) => {
          avgData[idx] += val / categories.length;
        });
      });
      
      const row = document.createElement('tr');
      row.className = 'model-row';
      row.innerHTML = `
        <td><strong>${modelNames[model]}</strong></td>
        ${avgData.map(val => `<td>${val.toFixed(3)}</td>`).join('')}
      `;
      tbody.appendChild(row);
    } else {
      // Show specific category
      const categoryKey = category.charAt(0).toUpperCase() + category.slice(1);
      if (humanEvalData[model][categoryKey]) {
        const data = humanEvalData[model][categoryKey];
        const row = document.createElement('tr');
        row.className = 'model-row';
        row.innerHTML = `
          <td><strong>${modelNames[model]}</strong></td>
          ${data.map(val => `<td>${val.toFixed(3)}</td>`).join('')}
        `;
        tbody.appendChild(row);
      }
    }
  });
}

function showEvalCategory(category) {
  populateHumanEvalTable(category);
  
  // Update active button
  document.querySelectorAll('.eval-controls .filter-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
}

// Event listeners
document.addEventListener('DOMContentLoaded', function() {
  populateVideoGallery();
  populateHumanEvalTable();
  
  // Initialize video count display
  const totalVideos = videoExamples.length;
  document.getElementById('totalCount').textContent = totalVideos;
  document.getElementById('visibleCount').textContent = totalVideos;
  
  // Add event listeners to filter buttons
  document.querySelectorAll('.filter-controls .filter-btn').forEach(btn => {
    btn.addEventListener('click', function() {
      const filter = this.dataset.filter;
      filterVideos(filter, this);
    });
  });
});
</script>

</body>
</html>
