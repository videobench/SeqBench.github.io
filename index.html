<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SeqBench: A comprehensive benchmark for evaluating sequential narrative coherence in text-to-video generation models.">
  <meta name="keywords" content="text-to-video, video generation, benchmark, sequential narrative, temporal coherence, T2V models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <style>
    .publication-title {
      font-family: 'Google Sans', sans-serif;
    }
    
    .hero.teaser {
      background: white;
      color: #333;
    }
    
    .teaser .hero-body {
      padding: 3rem 1.5rem;
    }
    
    .result-table {
      margin: 2rem 0;
      overflow-x: auto;
    }
    
    .result-table table {
      font-size: 0.85rem;
    }
    
    .methodology-step {
      background: #f8f9fa;
      border-radius: 8px;
      padding: 1.5rem;
      margin: 1rem 0;
      border-left: 4px solid #3273dc;
    }
    
    .dataset-category {
      background: white;
      border-radius: 8px;
      padding: 1.5rem;
      margin: 1rem 0;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .metric-comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin: 2rem 0;
    }
    
    @media (max-width: 768px) {
      .metric-comparison {
        grid-template-columns: 1fr;
      }
    }
    
    .highlight-number {
      font-size: 2rem;
      font-weight: bold;
      color: #3273dc;
    }
    
    .failure-mode {
      background: #fff5f5;
      border: 1px solid #fed7d7;
      border-radius: 8px;
      padding: 1rem;
      margin: 0.5rem 0;
    }
    
    .performance-card {
      background: white;
      border-radius: 8px;
      padding: 1.5rem;
      text-align: center;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      transition: transform 0.2s;
    }
    
    .performance-card:hover {
      transform: translateY(-2px);
    }
    
    .best-score {
      background: #e8f5e8;
      font-weight: bold;
    }
    
    .figure-container {
      text-align: center;
      margin: 2rem 0;
    }
    
    .figure-container img {
      max-width: 100%;
      height: auto;
      border-radius: 8px;
      box-shadow: 0 4px 16px rgba(0,0,0,0.1);
    }
    
    .video-gallery {
      background: #f8f9fa;
      padding: 2rem;
      border-radius: 12px;
      margin: 2rem 0;
    }
    
    .filter-controls {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin-bottom: 2rem;
      justify-content: center;
    }
    
    .filter-btn {
      padding: 0.5rem 1rem;
      border: 2px solid #3273dc;
      background: white;
      color: #3273dc;
      border-radius: 20px;
      cursor: pointer;
      transition: all 0.3s;
    }
    
    .filter-btn:hover, .filter-btn.active {
      background: #3273dc;
      color: white;
    }
    
    .video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 1.5rem;
      margin-top: 2rem;
    }
    
    .video-card {
      background: white;
      border-radius: 8px;
      padding: 1rem;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      transition: transform 0.2s;
    }
    
    .video-card:hover {
      transform: translateY(-2px);
    }
    
    .video-placeholder {
      width: 100%;
      height: 200px;
      background: #f0f0f0;
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      margin-bottom: 1rem;
      position: relative;
      overflow: hidden;
    }
    
    .video-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      margin-top: 0.5rem;
    }
    
    .video-tag {
      background: #e3f2fd;
      color: #1976d2;
      padding: 0.2rem 0.5rem;
      border-radius: 12px;
      font-size: 0.8rem;
    }
    
    .human-eval-section {
      background: #f8f9fa;
      padding: 2rem;
      border-radius: 12px;
      margin: 2rem 0;
    }
    
    .eval-controls {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      margin-bottom: 2rem;
      justify-content: center;
    }
    
    .eval-table {
      overflow-x: auto;
      background: white;
      border-radius: 8px;
      padding: 1rem;
    }
    
    .eval-table table {
      font-size: 0.8rem;
    }
    
    .model-row {
      border-left: 4px solid #3273dc;
    }
    
    .category-header {
      background: #e3f2fd;
      font-weight: bold;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Authors</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Institute</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/AcmmmVideobench/Acmmm2025_video_benchmark"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="figure-container">
        <!-- 替换为实际的主图 -->
        <img src="./static/images/main_fig.jpg" alt="Sequential narrative generation failures in current T2V models" 
             style="max-width: 100%; background: white; padding: 1rem; border-radius: 12px;">
        <figcaption style="margin-top: 1rem; color: #666; font-size: 1.1rem;">
          Examples of sequential narrative generation failures in current T2V models. 
          Each type demonstrates specific failure modes that SeqBench is designed to detect and evaluate.
        </figcaption>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Text-to-video (T2V) generation models have made significant progress in creating visually appealing videos. 
          However, they struggle with generating coherent sequential narratives that require logical progression through multiple events. 
          Existing T2V benchmarks primarily focus on visual quality metrics but fail to evaluate narrative coherence over extended sequences.
          </p>
          <p>
          To bridge this gap, we present <span style="font-weight: bold;">SeqBench</span>, a comprehensive benchmark for evaluating sequential narrative coherence in T2V generation.
          SeqBench includes a carefully designed dataset of 320 prompts spanning various narrative complexities, with 2,560 human-annotated videos generated from 8 state-of-the-art T2V models. 
          Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic evaluation metric, 
          which can efficiently capture long-range dependencies and temporal ordering while maintaining computational efficiency.
          Our DTG-based metric demonstrates a strong correlation with human annotations. 
          </p>
          <p>
          Through systematic evaluation using SeqBench, we reveal critical limitations in current T2V models: failure to maintain consistent object states across multi-action sequences, 
          physically implausible results in multi-object scenarios, and difficulties in preserving realistic timing and ordering relationships between sequential actions. 
          SeqBench provides the first systematic framework for evaluating narrative coherence in T2V generation and offers concrete insights for improving sequential reasoning capabilities in future models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Dataset Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Dataset Overview</h2>
        
        <div class="columns">
          <div class="column is-half">
            <div class="dataset-category">
              <h4 class="title is-4">Key Statistics</h4>
              <div class="columns is-multiline">
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">320</div>
                  <p>Carefully Designed Prompts</p>
                </div>
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">2,560</div>
                  <p>Human-Annotated Videos</p>
                </div>
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">8</div>
                  <p>State-of-the-art T2V Models</p>
                </div>
                <div class="column is-half has-text-centered">
                  <div class="highlight-number">4</div>
                  <p>Content Categories</p>
                </div>
              </div>
            </div>
          </div>
          
          <div class="column is-half">
            <div class="dataset-category">
              <h4 class="title is-4">Content Categories</h4>
              <div class="content">
                <p><strong>🐾 Animal:</strong> Animal behaviors and interactions, from simple locomotion to complex predatory behaviors</p>
                <p><strong>👤 Human:</strong> Human activities across various contexts, from daily routines to social interactions</p>
                <p><strong>📦 Object:</strong> Inanimate objects and their transformations, movements, or interactions</p>
                <p><strong>✨ Imaginary:</strong> Fantastical, supernatural, or stylized content beyond realistic constraints</p>
              </div>
            </div>
          </div>
        </div>

        <div class="columns">
          <div class="column">
            <div class="dataset-category">
              <h4 class="title is-4">Difficulty Levels</h4>
              <div class="columns is-multiline">
                <div class="column is-half">
                  <p><strong>SSSA:</strong> Single Subject-Single Action</p>
                  <p><strong>SSMA:</strong> Single Subject-Multi Action</p>
                </div>
                <div class="column is-half">
                  <p><strong>MSSA:</strong> Multi Subject-Single Action</p>
                  <p><strong>MSMA:</strong> Multi Subject-Multi Action</p>
                </div>
              </div>
            </div>
          </div>
          
          <div class="column">
            <div class="dataset-category">
              <h4 class="title is-4">Temporal Orders</h4>
              <div class="content">
                <p><strong>SS:</strong> Strictly Sequential - Actions follow predetermined logical sequence</p>
                <p><strong>FO:</strong> Flexible Order - Actions can occur in varying orders while maintaining coherence</p>
                <p><strong>SI:</strong> Simultaneous - Concurrent actions testing parallel process coordination</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Methodology Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Dynamic Temporal Graph (DTG) Evaluation</h2>
        
        <!-- DTG Method Figure -->
        <div class="figure-container">
          <img src="./static/images/video_bench_fig_3.png" alt="Dynamic Temporal Graph evaluation framework" 
               style="max-width: 100%;">
          <figcaption style="margin-top: 1rem; color: #666; font-size: 1rem;">
            Overview of the Dynamic Temporal Graph (DTG) evaluation framework showing temporal decomposition, 
            adaptive graph extraction, and dependency filtering processes.
          </figcaption>
        </div>
        
        <div class="content has-text-centered">
          <p class="is-size-5">Our evaluation framework assesses videos across two complementary dimensions</p>
        </div>

        <div class="metric-comparison">
          <div class="performance-card">
            <h4 class="title is-4">📊 Visual Details Evaluation</h4>
            <div class="content">
              <p>Assesses visual quality, object fidelity, and scene composition using frame-level analysis</p>
              <ul style="text-align: left;">
                <li>Frame-level scene graph extraction</li>
                <li>Object presence and attribute correctness</li>
                <li>Spatial relationship accuracy</li>
                <li>Scene composition quality</li>
              </ul>
            </div>
          </div>
          
          <div class="performance-card">
            <h4 class="title is-4">🎬 Narrative Coherence Evaluation</h4>
            <div class="content">
              <p>Measures temporal consistency and sequential logic using Dynamic Temporal Graphs</p>
              <ul style="text-align: left;">
                <li>Temporal decomposition</li>
                <li>Dynamic graph extraction</li>
                <li>Question-aware feature emphasis</li>
                <li>Dependency filtering</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="methodology-step">
          <h4 class="title is-4">🔍 Key Innovation: Adaptive Graph Extraction</h4>
          <div class="content">
            <p>Traditional scene graph extraction uses static templates that may miss narrative-specific details. Our <strong>Dynamic Temporal Graph</strong> approach:</p>
            <ul>
              <li><strong>Dynamic Prompt Generation:</strong> Customizes graph extraction prompts based on specific evaluation questions</li>
              <li><strong>Question-aware Feature Emphasis:</strong> Prioritizes tracking of exact features needed for accurate evaluation</li>
              <li><strong>Multi-frame Analysis:</strong> Extracts scene graphs from 15 distributed frames using adapted prompts</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Video Gallery Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Video Examples Gallery</h2>
    
    <div class="video-gallery">
      <div class="content has-text-centered">
        <p class="is-size-5">Explore 30 carefully selected video examples showcasing different content types, difficulty levels, and model performances</p>
      </div>
      
      <div class="filter-controls">
        <button class="filter-btn active" data-filter="all">All Videos</button>
        <button class="filter-btn" data-filter="animal">🐾 Animal</button>
        <button class="filter-btn" data-filter="human">👤 Human</button>
        <button class="filter-btn" data-filter="object">📦 Object</button>
        <button class="filter-btn" data-filter="imaginary">✨ Imaginary</button>
        <button class="filter-btn" data-filter="sssa">SSSA</button>
        <button class="filter-btn" data-filter="ssma">SSMA</button>
        <button class="filter-btn" data-filter="mssa">MSSA</button>
        <button class="filter-btn" data-filter="msma">MSMA</button>
        <button class="filter-btn" data-filter="kling">Kling 2.0</button>
        <button class="filter-btn" data-filter="cogvideo">Cogvideo 1.5</button>
        <button class="filter-btn" data-filter="hailuo">Hailuo T2V</button>
        <button class="filter-btn" data-filter="pika">Pika 2.2</button>
        <button class="filter-btn" data-filter="sora">Sora</button>
        <button class="filter-btn" data-filter="luma">Luma Ray2</button>
        <button class="filter-btn" data-filter="veo">Veo 2.0</button>
        <button class="filter-btn" data-filter="gen3">Gen3</button>
      </div>
      
      <div class="video-grid" id="videoGrid">
        <!-- Video examples will be populated here -->
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experimental Results</h2>
    
    <div class="content has-text-centered">
      <p class="is-size-5">Evaluation of 8 state-of-the-art T2V models reveals significant gaps between visual quality and narrative coherence</p>
    </div>

    <!-- Visual Details Results -->
    <div class="result-table">
      <h3 class="title is-4">Visual Details Evaluation Results</h3>
      <div style="overflow-x: auto;">
        <table class="table is-striped is-fullwidth">
          <thead>
            <tr>
              <th>Model</th>
              <th>SSMA_SS</th>
              <th>SSMA_FO</th>
              <th>SSMA_SI</th>
              <th>MSMA_SS</th>
              <th>MSMA_FO</th>
              <th>MSMA_SI</th>
              <th>SSSA</th>
              <th>MSSA</th>
              <th>Avg. Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Kling 2.0</strong></td>
              <td class="best-score">0.819</td>
              <td class="best-score">0.839</td>
              <td class="best-score">0.823</td>
              <td>0.693</td>
              <td class="best-score">0.734</td>
              <td class="best-score">0.713</td>
              <td>0.774</td>
              <td class="best-score">0.804</td>
              <td class="best-score">0.775</td>
            </tr>
            <tr>
              <td><strong>Cogvideo 1.5</strong></td>
              <td>0.806</td>
              <td>0.817</td>
              <td>0.814</td>
              <td class="best-score">0.700</td>
              <td>0.718</td>
              <td>0.711</td>
              <td class="best-score">0.780</td>
              <td>0.789</td>
              <td>0.767</td>
            </tr>
            <tr>
              <td><strong>Hailuo T2V-01</strong></td>
              <td>0.812</td>
              <td>0.826</td>
              <td>0.758</td>
              <td>0.654</td>
              <td>0.659</td>
              <td>0.650</td>
              <td>0.771</td>
              <td>0.780</td>
              <td>0.739</td>
            </tr>
            <tr>
              <td><strong>Pika 2.2</strong></td>
              <td>0.757</td>
              <td>0.762</td>
              <td>0.721</td>
              <td>0.565</td>
              <td>0.676</td>
              <td>0.595</td>
              <td>0.710</td>
              <td>0.733</td>
              <td>0.690</td>
            </tr>
            <tr>
              <td><strong>Sora</strong></td>
              <td>0.737</td>
              <td>0.764</td>
              <td>0.750</td>
              <td>0.549</td>
              <td>0.591</td>
              <td>0.608</td>
              <td>0.699</td>
              <td>0.693</td>
              <td>0.674</td>
            </tr>
            <tr>
              <td><strong>Luma Ray2</strong></td>
              <td>0.684</td>
              <td>0.681</td>
              <td>0.724</td>
              <td>0.518</td>
              <td>0.608</td>
              <td>0.543</td>
              <td>0.721</td>
              <td>0.676</td>
              <td>0.644</td>
            </tr>
            <tr>
              <td><strong>Veo 2.0</strong></td>
              <td>0.482</td>
              <td>0.585</td>
              <td>0.595</td>
              <td>0.523</td>
              <td>0.517</td>
              <td>0.476</td>
              <td>0.627</td>
              <td>0.578</td>
              <td>0.548</td>
            </tr>
            <tr>
              <td><strong>Runway Gen3</strong></td>
              <td>0.485</td>
              <td>0.552</td>
              <td>0.563</td>
              <td>0.383</td>
              <td>0.446</td>
              <td>0.442</td>
              <td>0.532</td>
              <td>0.470</td>
              <td>0.484</td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>

    <!-- Narrative Coherence Results -->
    <div class="result-table">
      <h3 class="title is-4">Narrative Coherence Evaluation Results</h3>
      <div style="overflow-x: auto;">
        <table class="table is-striped is-fullwidth">
          <thead>
            <tr>
              <th>Model</th>
              <th>SSMA_SS</th>
              <th>SSMA_FO</th>
              <th>SSMA_SI</th>
              <th>MSMA_SS</th>
              <th>MSMA_FO</th>
              <th>MSMA_SI</th>
              <th>SSSA</th>
              <th>MSSA</th>
              <th>Avg. Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Kling 2.0</strong></td>
              <td class="best-score">0.266</td>
              <td>0.209</td>
              <td>0.207</td>
              <td class="best-score">0.192</td>
              <td class="best-score">0.258</td>
              <td>0.228</td>
              <td>0.291</td>
              <td class="best-score">0.366</td>
              <td class="best-score">0.252</td>
            </tr>
            <tr>
              <td><strong>Hailuo T2V-01</strong></td>
              <td>0.212</td>
              <td class="best-score">0.230</td>
              <td>0.192</td>
              <td>0.179</td>
              <td>0.207</td>
              <td>0.199</td>
              <td class="best-score">0.345</td>
              <td>0.288</td>
              <td>0.231</td>
            </tr>
            <tr>
              <td><strong>Pika 2.2</strong></td>
              <td>0.219</td>
              <td>0.202</td>
              <td>0.194</td>
              <td>0.171</td>
              <td>0.238</td>
              <td class="best-score">0.229</td>
              <td>0.293</td>
              <td>0.277</td>
              <td>0.228</td>
            </tr>
            <tr>
              <td><strong>Cogvideo 1.5</strong></td>
              <td>0.222</td>
              <td>0.197</td>
              <td class="best-score">0.208</td>
              <td>0.189</td>
              <td>0.224</td>
              <td>0.191</td>
              <td>0.272</td>
              <td>0.235</td>
              <td>0.217</td>
            </tr>
            <tr>
              <td><strong>Veo 2.0</strong></td>
              <td>0.156</td>
              <td>0.180</td>
              <td>0.158</td>
              <td>0.184</td>
              <td>0.225</td>
              <td>0.190</td>
              <td>0.256</td>
              <td>0.262</td>
              <td>0.201</td>
            </tr>
            <tr>
              <td><strong>Luma Ray2</strong></td>
              <td>0.122</td>
              <td>0.174</td>
              <td>0.149</td>
              <td>0.171</td>
              <td>0.199</td>
              <td>0.146</td>
              <td>0.216</td>
              <td>0.262</td>
              <td>0.180</td>
            </tr>
            <tr>
              <td><strong>Sora</strong></td>
              <td>0.198</td>
              <td>0.161</td>
              <td>0.154</td>
              <td>0.123</td>
              <td>0.152</td>
              <td>0.171</td>
              <td>0.287</td>
              <td>0.180</td>
              <td>0.178</td>
            </tr>
            <tr>
              <td><strong>Runway Gen3</strong></td>
              <td>0.149</td>
              <td>0.137</td>
              <td>0.163</td>
              <td>0.115</td>
              <td>0.141</td>
              <td>0.163</td>
              <td>0.198</td>
              <td>0.170</td>
              <td>0.154</td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>
  </div>
</section>

<!-- Human Evaluation Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Human Evaluation Results</h2>
    
    <div class="human-eval-section">
      <div class="content has-text-centered">
        <p class="is-size-5">
          Detailed human evaluation across all models and categories with Overall, Action, and Consistency dimensions
        </p>
      </div>
      
      <div class="eval-controls">
        <button class="filter-btn active" onclick="showEvalCategory('all')">All Categories</button>
        <button class="filter-btn" onclick="showEvalCategory('animal')">🐾 Animal</button>
        <button class="filter-btn" onclick="showEvalCategory('human')">👤 Human</button>
        <button class="filter-btn" onclick="showEvalCategory('imaginary')">✨ Imaginary</button>
        <button class="filter-btn" onclick="showEvalCategory('object')">📦 Object</button>
      </div>
      
      <div class="eval-table">
        <div style="overflow-x: auto;">
          <table class="table is-striped is-fullwidth" id="humanEvalTable">
            <thead>
              <tr>
                <th rowspan="2">Model</th>
                <th colspan="3">MSMA-FO</th>
                <th colspan="3">MSMA-SI</th>
                <th colspan="3">MSMA-SS</th>
                <th colspan="3">MSSA</th>
                <th colspan="3">SSMA-FO</th>
                <th colspan="3">SSMA-SI</th>
                <th colspan="3">SSMA-SS</th>
                <th colspan="3">SSSA</th>
              </tr>
              <tr>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
                <th>Overall</th><th>Consistency</th><th>Action</th>
              </tr>
            </thead>
            <tbody id="humanEvalBody">
              <!-- Data will be populated by JavaScript -->
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX Section -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{seqbench2025,
  author    = {Anonymous Authors},
  title     = {SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models},
  journal   = {TBD},
  year      = {2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
// Human evaluation data from your provided table
const humanEvalData = {
  'cogvideo': {
    'Animal': [1.450000, 0.700000, 0.950000, 0.800000, 0.300000, 0.500000, 0.600000, 0.400000, 0.200000, 0.400000, 0.200000, 0.200000, 1.000000, 0.500000, 0.600000, 0.400000, 0.200000, 0.200000, 0.900000, 0.300000, 0.300000, 0.200000, 0.200000, 0.200000],
    'Human': [0.333333, 0.266667, 0.300000, 0.233333, 0.066667, 0.133333, 0.500000, 0.333333, 0.166667, 0.300000, 0.300000, 0.300000, 0.233333, 0.100000, 0.166667, 0.200000, 0.100000, 0.166667, 0.200000, 0.133333, 0.200000, 0.300000, 0.300000, 0.300000],
    'Imaginary': [0.566667, 0.566667, 0.133333, 0.466667, 0.216667, 0.400000, 0.583333, 0.533333, 0.050000, 0.400000, 0.650000, 0.250000, 0.650000, 0.600000, 0.400000, 0.650000, 0.650000, 0.250000, 0.750000, 0.550000, 0.550000, 0.650000, 0.650000, 0.250000],
    'Object': [0.800000, 0.300000, 0.500000, 1.050000, 0.350000, 0.700000, 0.750000, 0.700000, 0.050000, 0.500000, 0.550000, 0.750000, 0.850000, 0.250000, 0.550000, 0.550000, 0.400000, 0.750000, 0.700000, 0.250000, 0.550000, 0.550000, 0.400000, 0.750000]
  },
  'gen3': {
    'Animal': [0.100000, 0.100000, 0.050000, 0.200000, 0.400000, 0.350000, 0.150000, 0.000000, 0.700000, 0.600000, 0.150000, 0.100000, 0.350000, 0.150000, 0.150000, 0.300000, 0.350000, 0.150000, 0.450000, 0.200000, 0.200000, 0.300000, 0.250000, 0.150000, 0.100000],
    'Human': [0.233333, 0.133333, 0.233333, 0.133333, 0.100000, 0.100000, 0.333333, 0.200000, 0.133333, 0.300000, 0.350000, 0.150000, 0.350000, 0.300000, 0.350000, 0.350000, 0.200000, 0.300000, 0.400000, 0.300000, 0.350000, 0.350000, 0.150000, 0.150000, 0.100000],
    'Imaginary': [0.266667, 0.600000, 0.333333, 0.133333, 0.366667, 0.350000, 0.600000, 0.466667, 0.133333, 0.500000, 0.250000, 0.300000, 0.450000, 0.550000, 0.450000, 0.650000, 0.650000, 0.300000, 0.550000, 0.350000, 0.300000, 0.350000, 0.350000, 0.300000],
    'Object': [0.650000, 0.200000, 0.450000, 0.550000, 0.250000, 0.450000, 0.750000, 0.700000, 0.050000, 0.500000, 0.750000, 0.900000, 0.700000, 0.450000, 0.500000, 0.750000, 0.550000, 0.650000, 0.900000, 0.600000, 0.650000, 0.750000, 0.700000, 0.200000, 0.900000]
  },
  'hailuo': {
    'Animal': [1.150000, 0.750000, 0.600000, 1.000000, 0.900000, 0.900000, 0.900000, 0.900000, 0.000000, 0.600000, 0.650000, 0.550000, 0.800000, 0.800000, 0.600000, 0.650000, 0.650000, 0.550000, 0.650000, 0.650000, 0.550000, 1.000000, 0.650000, 0.650000, 0.550000],
    'Human': [0.733333, 0.500000, 0.366667, 0.700000, 0.350000, 0.500000, 0.700000, 0.533333, 0.266667, 0.250000, 0.700000, 0.400000, 0.600000, 0.450000, 0.650000, 0.650000, 0.400000, 0.400000, 0.650000, 0.650000, 0.400000, 0.650000, 0.650000, 0.400000, 0.400000],
    'Imaginary': [0.566667, 0.500000, 0.200000, 0.766667, 0.600000, 0.666667, 0.700000, 0.700000, 0.000000, 0.600000, 0.450000, 0.550000, 0.650000, 0.550000, 0.550000, 0.650000, 0.650000, 0.550000, 0.600000, 0.600000, 0.550000, 0.800000, 0.550000, 0.550000, 0.550000],
    'Object': [1.100000, 0.600000, 0.700000, 0.650000, 0.450000, 0.500000, 0.700000, 0.700000, 0.000000, 0.450000, 0.500000, 0.750000, 0.650000, 0.500000, 0.500000, 0.650000, 0.650000, 0.500000, 0.500000, 0.500000, 0.500000, 0.850000, 0.500000, 0.500000, 0.750000]
  },
  'luma': {
    'Animal': [0.900000, 0.650000, 0.250000, 0.800000, 0.600000, 0.750000, 0.850000, 0.800000, 0.050000, 0.650000, 0.600000, 0.450000, 0.650000, 0.600000, 0.450000, 0.650000, 0.650000, 0.450000, 0.750000, 0.750000, 0.450000, 0.800000, 0.650000, 0.450000, 0.450000],
    'Human': [0.533333, 0.333333, 0.200000, 0.500000, 0.350000, 0.300000, 0.600000, 0.500000, 0.100000, 0.450000, 0.650000, 0.350000, 0.350000, 0.300000, 0.200000, 0.550000, 0.450000, 0.300000, 0.600000, 0.350000, 0.300000, 0.650000, 0.350000, 0.250000, 0.300000],
    'Imaginary': [0.666667, 0.750000, 0.350000, 0.500000, 0.700000, 0.550000, 0.900000, 0.800000, 0.100000, 0.700000, 0.550000, 0.600000, 0.800000, 0.750000, 0.600000, 0.750000, 0.750000, 0.600000, 0.850000, 0.800000, 0.550000, 0.900000, 0.800000, 0.550000, 0.550000],
    'Object': [1.250000, 0.600000, 0.700000, 0.800000, 0.350000, 0.400000, 1.000000, 0.900000, 0.200000, 0.050000, 0.650000, 0.800000, 0.550000, 0.350000, 0.450000, 0.950000, 0.850000, 0.450000, 0.700000, 0.550000, 0.450000, 0.650000, 0.800000, 0.250000, 0.800000]
  },
  'pika': {
    'Animal': [1.150000, 0.350000, 0.750000, 0.700000, 0.350000, 0.900000, 0.900000, 0.750000, 0.200000, 0.000000, 0.650000, 0.550000, 0.950000, 0.900000, 0.650000, 0.550000, 0.550000, 0.650000, 0.900000, 0.850000, 0.650000, 0.550000, 0.250000, 0.300000],
    'Human': [0.433333, 0.466667, 0.233333, 0.433333, 0.366667, 0.200000, 0.566667, 0.400000, 0.166667, 0.350000, 0.400000, 0.250000, 0.350000, 0.300000, 0.300000, 0.450000, 0.450000, 0.300000, 0.700000, 0.350000, 0.300000, 0.250000, 0.300000, 0.000000],
    'Imaginary': [1.033333, 0.666667, 0.533333, 1.033333, 0.800000, 0.700000, 0.800000, 0.800000, 0.000000, 0.700000, 0.850000, 0.900000, 0.850000, 0.750000, 0.850000, 0.900000, 0.900000, 0.750000, 1.050000, 0.850000, 0.850000, 1.050000, 0.850000, 0.900000],
    'Object': [0.900000, 0.600000, 0.400000, 1.150000, 0.650000, 0.800000, 0.900000, 0.900000, 0.300000, 0.350000, 0.500000, 0.700000, 0.650000, 0.400000, 0.450000, 0.900000, 0.850000, 0.450000, 0.750000, 0.650000, 0.450000, 0.750000, 0.650000, 0.700000]
  },
  'sora': {
    'Animal': [0.450000, 0.500000, 0.150000, 0.500000, 0.400000, 0.100000, 0.650000, 0.550000, 0.050000, 0.400000, 0.400000, 0.300000, 0.400000, 0.400000, 0.300000, 0.550000, 0.500000, 0.300000, 0.450000, 0.400000, 0.300000, 0.700000, 0.400000, 0.300000],
    'Human': [0.333333, 0.166667, 0.133333, 0.233333, 0.066667, 0.066667, 0.350000, 0.300000, 0.050000, 0.350000, 0.300000, 0.350000, 0.300000, 0.200000, 0.200000, 0.350000, 0.350000, 0.200000, 0.300000, 0.300000, 0.200000, 0.350000, 0.200000, 0.350000],
    'Imaginary': [0.133333, 0.566667, 0.333333, 0.166667, 0.166667, 0.150000, 0.300000, 0.450000, 0.200000, 0.050000, 0.250000, 0.350000, 0.250000, 0.500000, 0.350000, 0.500000, 0.500000, 0.350000, 0.250000, 0.450000, 0.350000, 0.550000, 0.500000, 0.350000],
    'Object': [0.700000, 0.400000, 0.500000, 0.850000, 0.550000, 0.300000, 0.550000, 0.550000, 0.300000, 0.050000, 0.750000, 0.550000, 0.650000, 0.650000, 0.550000, 0.750000, 0.800000, 0.550000, 0.700000, 0.700000, 0.550000, 1.050000, 0.300000, 0.900000]
  },
  'veo': {
    'Animal': [1.400000, 0.550000, 0.850000, 1.400000, 0.700000, 1.100000, 0.900000, 0.900000, 0.000000, 0.700000, 0.450000, 0.150000, 0.800000, 0.650000, 0.450000, 0.900000, 0.850000, 0.450000, 0.900000, 0.850000, 0.450000, 0.850000, 0.800000, 0.150000, 0.150000],
    'Human': [0.866667, 0.266667, 0.766667, 0.466667, 0.200000, 0.666667, 0.600000, 0.500000, 0.400000, 0.450000, 0.850000, 0.700000, 0.550000, 0.300000, 0.550000, 0.700000, 0.650000, 0.550000, 0.850000, 0.650000, 0.450000, 0.850000, 0.850000, 0.450000, 0.700000],
    'Imaginary': [0.600000, 0.600000, 0.400000, 0.633333, 0.566667, 0.400000, 0.600000, 0.550000, 0.050000, 0.350000, 0.400000, 0.550000, 0.500000, 0.350000, 0.400000, 0.850000, 0.800000, 0.550000, 0.700000, 0.650000, 0.550000, 1.000000, 0.850000, 0.550000, 0.550000],
    'Object': [1.250000, 0.750000, 0.700000, 1.250000, 0.550000, 0.700000, 0.900000, 0.900000, 0.000000, 0.150000, 0.850000, 0.650000, 0.900000, 0.850000, 0.650000, 0.900000, 0.850000, 0.650000, 1.100000, 0.900000, 0.650000, 1.100000, 0.900000, 0.350000, 0.850000]
  }
};

// Video examples data - 精选30个核心代表性视频
const videoExamples = [
  // === HUMAN 类别 (8个视频) ===
  {
    path: "video_bench/human/sssa/kling/2.mp4",
    category: "human",
    difficulty: "sssa",
    model: "Kling 2.0"
  },
  {
    path: "video_bench/human/mssa/cogvideo/5.mp4",
    category: "human", 
    difficulty: "mssa",
    model: "Cogvideo 1.5"
  },
  {
    path: "video_bench/human/ssma_fo/hailuo/1.mp4",
    category: "human",
    difficulty: "ssma_fo", 
    model: "Hailuo T2V-01"
  },
  {
    path: "video_bench/human/ssma_sim/pika/6.mp4",
    category: "human",
    difficulty: "ssma_sim",
    model: "Pika 2.2"
  },
  {
    path: "video_bench/human/ssma_ss/sora/3.mp4",
    category: "human",
    difficulty: "ssma_ss",
    model: "Sora"
  },
  {
    path: "video_bench/human/msma_fo/luma/8.mp4",
    category: "human",
    difficulty: "msma_fo",
    model: "Luma Ray2"
  },
  {
    path: "video_bench/human/msma_sim/veo/4.mp4",
    category: "human",
    difficulty: "msma_sim",
    model: "Veo 2.0"
  },
  {
    path: "video_bench/human/msma_ss/gen3/7.mp4",
    category: "human",
    difficulty: "msma_ss",
    model: "Runway Gen3"
  },

  // === ANIMAL 类别 (8个视频) ===
  {
    path: "video_bench/animal/sssa/kling/3.mp4",
    category: "animal",
    difficulty: "sssa",
    model: "Kling 2.0"
  },
  {
    path: "video_bench/animal/mssa/hailuo/6.mp4",
    category: "animal",
    difficulty: "mssa",
    model: "Hailuo T2V-01"
  },
  {
    path: "video_bench/animal/ssma_fo/cogvideo/1.mp4",
    category: "animal",
    difficulty: "ssma_fo",
    model: "Cogvideo 1.5"
  },
  {
    path: "video_bench/animal/ssma_sim/pika/8.mp4",
    category: "animal",
    difficulty: "ssma_sim",
    model: "Pika 2.2"
  },
  {
    path: "video_bench/animal/ssma_ss/sora/2.mp4",
    category: "animal",
    difficulty: "ssma_ss",
    model: "Sora"
  },
  {
    path: "video_bench/animal/msma_fo/luma/5.mp4",
    category: "animal",
    difficulty: "msma_fo",
    model: "Luma Ray2"
  },
  {
    path: "video_bench/animal/msma_sim/veo/9.mp4",
    category: "animal",
    difficulty: "msma_sim",
    model: "Veo 2.0"
  },
  {
    path: "video_bench/animal/msma_ss/gen3/0.mp4",
    category: "animal",
    difficulty: "msma_ss",
    model: "Runway Gen3"
  },

  // === OBJECT 类别 (7个视频) ===
  {
    path: "video_bench/object/sssa/kling/4.mp4",
    category: "object",
    difficulty: "sssa",
    model: "Kling 2.0"
  },
  {
    path: "video_bench/object/mssa/hailuo/7.mp4",
    category: "object",
    difficulty: "mssa",
    model: "Hailuo T2V-01"
  },
  {
    path: "video_bench/object/ssma_fo/cogvideo/2.mp4",
    category: "object",
    difficulty: "ssma_fo",
    model: "Cogvideo 1.5"
  },
  {
    path: "video_bench/object/ssma_sim/pika/9.mp4",
    category: "object",
    difficulty: "ssma_sim",
    model: "Pika 2.2"
  },
  {
    path: "video_bench/object/ssma_ss/sora/1.mp4",
    category: "object",
    difficulty: "ssma_ss",
    model: "Sora"
  },
  {
    path: "video_bench/object/msma_fo/luma/6.mp4",
    category: "object",
    difficulty: "msma_fo",
    model: "Luma Ray2"
  },
  {
    path: "video_bench/object/msma_sim/veo/3.mp4",
    category: "object",
    difficulty: "msma_sim",
    model: "Veo 2.0"
  },

  // === IMAGINARY 类别 (7个视频) ===
  {
    path: "video_bench/imaginary/sssa/hailuo/2.mp4",
    category: "imaginary",
    difficulty: "sssa",
    model: "Hailuo T2V-01"
  },
  {
    path: "video_bench/imaginary/mssa/kling/5.mp4",
    category: "imaginary",
    difficulty: "mssa",
    model: "Kling 2.0"
  },
  {
    path: "video_bench/imaginary/ssma_fo/pika/8.mp4",
    category: "imaginary",
    difficulty: "ssma_fo",
    model: "Pika 2.2"
  },
  {
    path: "video_bench/imaginary/ssma_sim/cogvideo/0.mp4",
    category: "imaginary",
    difficulty: "ssma_sim",
    model: "Cogvideo 1.5"
  },
  {
    path: "video_bench/imaginary/ssma_ss/sora/7.mp4",
    category: "imaginary",
    difficulty: "ssma_ss",
    model: "Sora"
  },
  {
    path: "video_bench/imaginary/msma_fo/luma/4.mp4",
    category: "imaginary",
    difficulty: "msma_fo",
    model: "Luma Ray2"
  },
  {
    path: "video_bench/imaginary/msma_sim/veo/9.mp4",
    category: "imaginary",
    difficulty: "msma_sim",
    model: "Veo 2.0"
  }
];

function populateVideoGallery() {
  const grid = document.getElementById('videoGrid');
  grid.innerHTML = '';
  
  videoExamples.forEach((video, index) => {
    const card = document.createElement('div');
    card.className = `video-card ${video.category} ${video.difficulty}`;
    
    // 生成视频标题
    const difficultyLabels = {
      'sssa': 'Single Subject-Single Action',
      'mssa': 'Multi Subject-Single Action', 
      'ssma_fo': 'Single Subject-Multi Action (Flexible Order)',
      'ssma_sim': 'Single Subject-Multi Action (Simultaneous)',
      'ssma_ss': 'Single Subject-Multi Action (Strictly Sequential)',
      'msma_fo': 'Multi Subject-Multi Action (Flexible Order)',
      'msma_sim': 'Multi Subject-Multi Action (Simultaneous)', 
      'msma_ss': 'Multi Subject-Multi Action (Strictly Sequential)'
    };
    
    const categoryIcons = {
      'human': '👤',
      'animal': '🐾', 
      'object': '📦',
      'imaginary': '✨'
    };
    
    card.innerHTML = `
      <div class="video-placeholder">
        <video controls style="width: 100%; height: 100%; object-fit: cover; border-radius: 8px;">
          <source src="${video.path}" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <h5 class="title is-6">${categoryIcons[video.category]} ${video.category.charAt(0).toUpperCase() + video.category.slice(1)} - ${video.model}</h5>
      <p class="is-size-7">${difficultyLabels[video.difficulty]}</p>
      <div class="video-tags">
        <span class="video-tag">${video.model}</span>
        <span class="video-tag">${video.category}</span>
        <span class="video-tag">${video.difficulty.toUpperCase()}</span>
      </div>
    `;
    grid.appendChild(card);
  });
}

function filterVideos(filter) {
  const cards = document.querySelectorAll('.video-card');
  cards.forEach(card => {
    if (filter === 'all') {
      card.style.display = 'block';
    } else {
      // 检查类别过滤
      if (card.classList.contains(filter)) {
        card.style.display = 'block';
      }
      // 检查难度级别过滤 (SSMA包含所有ssma_*类型)
      else if (filter === 'ssma' && (card.classList.contains('ssma_fo') || card.classList.contains('ssma_sim') || card.classList.contains('ssma_ss'))) {
        card.style.display = 'block';
      }
      // 检查MSMA过滤
      else if (filter === 'msma' && (card.classList.contains('msma_fo') || card.classList.contains('msma_sim') || card.classList.contains('msma_ss'))) {
        card.style.display = 'block';
      }
      // 检查模型过滤
      else if (filter === 'kling' && card.innerHTML.includes('Kling 2.0')) {
        card.style.display = 'block';
      }
      else if (filter === 'cogvideo' && card.innerHTML.includes('Cogvideo 1.5')) {
        card.style.display = 'block';
      }
      else if (filter === 'hailuo' && card.innerHTML.includes('Hailuo T2V-01')) {
        card.style.display = 'block';
      }
      else if (filter === 'pika' && card.innerHTML.includes('Pika 2.2')) {
        card.style.display = 'block';
      }
      else if (filter === 'sora' && card.innerHTML.includes('Sora')) {
        card.style.display = 'block';
      }
      else if (filter === 'luma' && card.innerHTML.includes('Luma Ray2')) {
        card.style.display = 'block';
      }
      else if (filter === 'veo' && card.innerHTML.includes('Veo 2.0')) {
        card.style.display = 'block';
      }
      else if (filter === 'gen3' && card.innerHTML.includes('Runway Gen3')) {
        card.style.display = 'block';
      }
      else {
        card.style.display = 'none';
      }
    }
  });
}

function populateHumanEvalTable(category = 'all') {
  const tbody = document.getElementById('humanEvalBody');
  tbody.innerHTML = '';
  
  const models = ['cogvideo', 'gen3', 'hailuo', 'luma', 'pika', 'sora', 'veo'];
  const modelNames = {
    'cogvideo': 'Cogvideo 1.5',
    'gen3': 'Runway Gen3', 
    'hailuo': 'Hailuo T2V-01',
    'luma': 'Luma Ray2',
    'pika': 'Pika 2.2',
    'sora': 'Sora',
    'veo': 'Veo 2.0'
  };
  
  models.forEach(model => {
    if (category === 'all') {
      // Show average across all categories
      const categories = ['Animal', 'Human', 'Imaginary', 'Object'];
      const avgData = new Array(24).fill(0);
      
      categories.forEach(cat => {
        const data = humanEvalData[model][cat];
        data.forEach((val, idx) => {
          avgData[idx] += val / categories.length;
        });
      });
      
      const row = document.createElement('tr');
      row.className = 'model-row';
      row.innerHTML = `
        <td><strong>${modelNames[model]}</strong></td>
        ${avgData.map(val => `<td>${val.toFixed(3)}</td>`).join('')}
      `;
      tbody.appendChild(row);
    } else {
      // Show specific category
      const categoryKey = category.charAt(0).toUpperCase() + category.slice(1);
      if (humanEvalData[model][categoryKey]) {
        const data = humanEvalData[model][categoryKey];
        const row = document.createElement('tr');
        row.className = 'model-row';
        row.innerHTML = `
          <td><strong>${modelNames[model]}</strong></td>
          ${data.map(val => `<td>${val.toFixed(3)}</td>`).join('')}
        `;
        tbody.appendChild(row);
      }
    }
  });
}

function showEvalCategory(category) {
  populateHumanEvalTable(category);
  
  // Update active button
  document.querySelectorAll('.eval-controls .filter-btn').forEach(btn => {
    btn.classList.remove('active');
  });
  event.target.classList.add('active');
}

// Event listeners
document.addEventListener('DOMContentLoaded', function() {
  populateVideoGallery();
  populateHumanEvalTable();
  
  // Add event listeners to filter buttons
  document.querySelectorAll('.filter-controls .filter-btn').forEach(btn => {
    btn.addEventListener('click', function(event) {
      const filter = this.dataset.filter;
      filterVideos(filter);
      
      // Update active button
      document.querySelectorAll('.filter-controls .filter-btn').forEach(b => {
        b.classList.remove('active');
      });
      this.classList.add('active');
    });
  });
});
</script>

</body>
</html>
